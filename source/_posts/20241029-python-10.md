---
title: '주말에 만들 수 있는 5가지 AI 프로젝트 (Python 사용)'
categories:
  - Programming
  - Language
  - Python
tags:
  - Programming
  - Python
  - Software Engineering
  - Coding
date: 2024-10-29 14:26:40
thumbnail: /images/thumbnail/python.png
---

AI 기술을 향상시키는 최고의 방법은 프로젝트를 직접 구축해 보는 것입니다. 그러나 어떤 프로젝트를 시작해야 할지 결정하기 어려울 때도 있습니다. 이 글에서는 초급부터 고급까지 세 가지 수준에서 빠르게 구축할 수 있는 5가지 AI 프로젝트 아이디어를 공유합니다. 각 아이디어를 구현하는 데 필요한 단계와 Python 라이브러리를 설명해드리겠습니다.

프로젝트 아이디어를 생각할 때, 초보자들이 가장 많이 하는 실수는 "**이 새로운 기술을 어떻게 사용할 수 있을까?**"라는 질문에서 시작하는 것입니다. 물론, 새로운 도구를 배우는 방법으로는 괜찮지만, 더 나은 접근법이 있습니다.

좋은 프로젝트 아이디어는 "**내가 해결할 수 있는 문제가 무엇인가?**"라는 질문에서 시작됩니다. 문제 해결은 기술을 가치로 전환하는 방법이며, 잠재적 고용주에게도 설득력 있는 스토리가 됩니다.

다음 프로젝트들은 모두 이 문제 해결 접근법을 따릅니다. 아이디어를 그대로 구현하거나, 더 나아가 개인적으로 해결하고 싶은 문제에 적용할 수도 있습니다.

## 1) 이력서 최적화 (초급)

구직 활동에서 시간이 많이 소요되는 작업 중 하나는 각 채용 공고에 맞게 이력서를 조정하는 것입니다. 과거에는 이러한 작업을 자동화하는 것이 고급 프로젝트에 속했지만, 오늘날의 LLM(Large Language Model) 덕분에 이제는 간단한 API 호출만으로도 해결할 수 있습니다.

**구현 단계:**

- 이력서를 Markdown 형식으로 작성합니다. (참고: ChatGPT를 통해 이 작업을 쉽게 할 수 있습니다).
- Markdown 이력서와 채용 공고를 받아 새롭게 이력서를 작성하는 다양한 프롬프트 템플릿을 실험해봅니다.
- OpenAI의 Python API를 사용해 GPT-4o-mini를 통해 이력서를 동적으로 수정합니다.
- `markdown` 및 `pdfkit` 라이브러리를 각각 사용하여 Markdown 파일을 HTML과 PDF로 변환합니다.

**사용 라이브러리:** `openai`, `markdown`, `pdfkit`

ChatGPT를 통해 간단히 이 작업을 처리할 수 있지만, Python으로 구현하면 더 쉽게 대규모 처리를 할 수 있습니다. 아래는 Step 3의 시작 코드입니다.

```python
import openai
openai.api_key = "your_sk"

# 프롬프트 (md_resume 및 job_desciption이 정의되어 있다고 가정)
prompt = f"""
Markdown 형식의 이력서와 채용 공고가 있습니다. \
이력서를 채용 요구 사항에 더 잘 맞게 조정해 주세요. \
필요한 기술, 경험, 성과를 강조하여 이력서를 수정해 주세요. \
이력서에는 여전히 나만의 독특한 자격과 강점이 반영되도록 하되, \
채용 공고와 일치하는 기술과 경험이 강조되도록 해주세요.

### 여기에 내 이력서 (Markdown 형식):
{md_resume}

### 여기에 채용 공고:
{job_desciption}

이력서를 수정해 주세요:
- 채용 공고의 키워드와 구문을 사용하세요.
- 각 역할 아래에 관련 기술과 성과를 강조하세요.
- 나의 경험이 요구되는 자격에 맞게 잘 나타나도록 수정해 주세요.
- 명확성, 간결성, 그리고 전문성을 유지하세요.

업데이트된 이력서를 Markdown 형식으로 반환해 주세요.

"""

# API 호출
response = openai.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": prompt}
    ],
    temperature = 0.25
)

# 응답 추출
resume = response.choices[0].message.content
```

참고: ChatGPT는 짧은 코드 스니펫(및 프롬프트)을 작성할 때 매우 유용합니다. Step 4에서 막히면 ChatGPT에 도움을 요청해 보세요!

## 2) YouTube 강의 요약 도구 (초급)

기술 강연을 YouTube의 "**나중에 보기**" 목록에 추가해 두는 것을 좋아하지만, 나중에 보려다 보지 못할 때가 많습니다. 이러한 문제를 해결하기 위해 동영상을 대신 시청하고 주요 포인트로 구성된 요약을 생성해 주는 도구를 만들 수 있습니다.

**구현 방법:**

- 정규 표현식을 사용하여 YouTube 비디오 링크에서 비디오 ID를 추출합니다.
- `youtube-transcript-api`를 사용해 비디오 ID로 트랜스크립트를 추출합니다.
- 트랜스크립트를 효과적으로 요약하는 다양한 ChatGPT 프롬프트를 실험해 봅니다.
- OpenAI의 Python API를 사용하여 이 과정을 자동화합니다.

**사용 라이브러리:** `openai`, `youtube-transcript-api`

기술적으로, 이 프로젝트는 앞서 소개한 프로젝트와 유사합니다. 다만, 이 프로젝트에서는 비디오 트랜스크립트를 자동으로 추출하여 언어 모델(LLM)에 입력해야 한다는 점이 다릅니다.

```python
import re
from youtube_transcript_api import YouTubeTranscriptApi

youtube_url = "video link here"

# 정규 표현식으로 비디오 ID 추출
video_id_regex = r'(?:v=|\/)([0-9A-Za-z_-]{11}).*'
match = re.search(video_id_regex, youtube_url)

if match:
    return match.group(1)
else:
    return None

# 트랜스크립트 추출
text_list = [transcript[i]['text'] for i in range(len(transcript))]
transcript_text = '\n'.join(text_list)
```

## 3) PDF 자동 정리 도구 (중급)

데스크탑에는 정리되지 않은 논문(PDF)들이 쌓여 있을 수 있습니다. 수동으로 이러한 논문을 검토하는 것은 시간이 많이 걸리기 때문에, AI를 활용해 보겠습니다.

데스크탑에 있는 각 PDF의 내용을 분석하고 주제별로 폴더를 만들어 자동으로 정리하는 도구를 구축할 수 있습니다. 텍스트 임베딩을 사용해 각 논문을 밀집 벡터 표현으로 변환한 뒤, 유사한 논문끼리 K-Means와 같은 전통적인 머신러닝 알고리즘으로 클러스터링할 수 있습니다.

**구현 방법:**

- `PyMuPDF`를 사용하여 각 논문의 초록을 읽습니다.
- `sentence-transformers` 라이브러리를 사용하여 초록을 텍스트 임베딩으로 변환하고, 이를 Pandas 데이터프레임에 저장합니다.
- `sklearn`의 선호하는 클러스터링 알고리즘을 사용하여 임베딩을 유사성 기반으로 그룹화합니다.
- 각 클러스터에 대한 폴더를 생성하고, 파일을 해당 폴더로 이동합니다.

**사용 라이브러리:** `PyMuPDF`, `sentence_transformers`, `pandas`, `sklearn`

이 프로젝트의 핵심 단계는 텍스트 임베딩 생성입니다. 다음은 `sentence_transformers`를 사용하여 임베딩을 생성하는 코드 예시입니다.

```python
from sentence_transformers import SentenceTransformer

# 임베딩 모델 로드
model = SentenceTransformer("all-MiniLM-L6-v2")

# 초록을 목록에 저장
abstract_list = ["abstract 1", "abstract 2"]

# 임베딩 계산
embeddings = model.encode(abstract_list)
```

## 4) 멀티모달 검색 시스템 (중급)

특정 기술 보고서들을 위한 기본적인 RAG(검색 증강 생성) 시스템을 구축할 때, 보고서의 주요 정보가 **텍스트가 아닌 플롯과 그림**으로 표현되는 경우가 많아 검색에 어려움을 겪을 수 있습니다.

시각적 정보를 검색 과정에 포함시키기 위해 **텍스트와 이미지를 동일한 공간에 표현하는 멀티모달 임베딩 모델**을 사용하는 방법이 있습니다.

**구현 단계:**

- PDF를 섹션별로 나누고, PyMuPDF를 사용해 이미지를 추출합니다.
- nomic-ai/nomic-embed-text-v1.5와 같은 멀티모달 임베딩 모델을 사용해 각 섹션과 이미지를 밀집 벡터로 표현하고, 데이터프레임에 저장합니다.
- 지식 베이스에 있는 모든 PDF에 대해 이 작업을 반복합니다.
- 사용자가 쿼리를 입력하면 지식 베이스에서 사용한 동일한 임베딩 모델을 통해 쿼리를 임베딩으로 변환합니다.
- 쿼리 임베딩과 지식 베이스 항목의 임베딩 간 코사인 유사도 점수를 계산합니다.
- 상위 k개의 결과를 반환합니다.

**사용 라이브러리:** `PyMuPDF`, `transformers`, `pandas`, `sklearn`

이 프로젝트의 중요한 부분은 PDF를 어떻게 나누느냐에 있습니다. 가장 간단한 방법은 고정된 문자 수를 기준으로 약간의 중첩을 포함하여 나누는 것입니다. 또한, 각 청크에 파일 이름과 페이지 번호 같은 메타데이터를 포함하는 것이 유용합니다.

아래는 기본 코드 예시입니다.

```python
import fitz  # PyMuPDF

def extract_text_chunks(pdf_path, chunk_size, overlap_size):
    # PDF 파일 열기
    pdf_document = fitz.open(pdf_path)
    chunks = []

    # 각 페이지를 반복하여 처리
    for page_num in range(len(pdf_document)):
        page = pdf_document[page_num]
        page_text = page.get_text()

        # 현재 페이지의 텍스트를 중첩을 포함하여 청크로 분할
        start = 0
        while start < len(page_text):
            end = start + chunk_size
            chunk = page_text[start:end]

            # 청크와 페이지 번호 저장
            chunks.append((page_num + 1, chunk))
            # 중첩 크기만큼 이동하여 다음 청크 설정
            start += chunk_size - overlap_size

    return chunks

# 추출 매개 변수 설정
pdf_path = "your_file.pdf"
chunk_size = 1000  # 각 텍스트 청크의 크기 (문자 수 기준)
overlap_size = 200  # 중첩 크기 (문자 수 기준)

text_chunks = extract_text_chunks(pdf_path, chunk_size, overlap_size)

# 페이지 번호와 함께 청크 출력
for i, (page_number, chunk) in enumerate(text_chunks):
    print(f"청크 {i + 1} (페이지 {page_number}):\n{chunk}\n{'-' * 50}")
```

## 5) 지식 기반 질문-응답(QA) 시스템 (고급)

가장 자주 요청받은 프로젝트가 바로 문서 질문-응답(QA) 시스템입니다. 이전 프로젝트를 기반으로, 이를 간단하게 구현할 수 있습니다.

**구현 단계:**

- 지식 베이스에서 검색을 수행합니다 (프로젝트 4에서 만든 것처럼).
- 사용자 쿼리와 상위 k개의 검색 결과를 결합하여 멀티모달 모델에 전달합니다.
- 질문-응답 시스템을 위한 간단한 Gradio 사용자 인터페이스를 생성합니다.

**사용 라이브러리:** `PyMuPDF`, `transformers`, `pandas`, `sklearn`, `together/openai`, `Gradio`

참고: Together AI의 API를 통해 Llama 3.2 Vision을 2025년까지 무료로 사용할 수 있습니다.

이 프로젝트는 본질적으로 프로젝트 2와 4를 결합한 형태입니다. 그러나 여기에는 사용자 인터페이스가 필수 요소로 포함됩니다. Gradio와 같은 대시보드 도구를 사용하여 간단한 채팅 UI를 몇 줄의 코드로 만들 수 있습니다.

아래는 Gradio의 문서에서 가져온 예시 코드입니다.

```python
import gradio as gr
import time

def generate_response(message, history):
    """
        응답을 생성하는 코드 작성
    """
    return response

demo = gr.ChatInterface(
    fn=generate_response,
    examples=[{"text": "Hello", "files": []}],
    title="Echo Bot",
    multimodal=True
)

demo.launch()
```
