---
title: '[TensorFlow 2.0] 각 Layer별 역할 및 파라미터'
categories:
  - Programming
  - AI
tags:
  - AI
  - Tensorflow
date: 2020-07-20 16:39:18
thumbnail:
---

## Layer Explaination

### Load Packages

```python
import tensorflow as tf
import os

import matplotlib.pyplot as plt
%matplotlib inline
```

### Input Image

```python
from tensorflow.keras import datasets

(train_x, train_y), (test_x, test_y) = datasets.mnist.load_data()
image = train_x[0]

# 차원 수 높이기
image = image[tf.newaxis, ..., tf.newaxis]
image.shape

# Out
(1, 28, 28, 1)
```

## Feature Extraction

![](/images/ai/dev/4.png)

### Convolution

![](/images/ai/dev/5.png)

- filters: layer에서 나갈 때 몇 개의 filter를 만들 것인지
- kernel_size: filter(Weight)의 크기
- strides: 몇 개의 pixel을 skip 하면서 훑어지나갈 것인지 (크기에도 영향을 준다)
- padding: zero padding을 만들 것인지. VALID는 padding이 없고, SAME은 padding이 있다. (크기에도 영향을 준다)
- activation: Activation Function을 만들 것인지. 당장 설정 안해도 Layer 층을 따로 만들 수 있다. (Default: None)

tf.keras.layers.Conv2D

```python
tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3), strides=(1, 1), padding='VALID', activation='relu')

# (3, 3) 대신에 3으로도 대체 가능
tf.keras.layers.Conv2D(3, 3, 1, 'VALID')
```

### Visualization

```python
image = tf.cast(image, dtype=tf.float32)

layer = tf.keras.layers.Conv2D(3, 3, strides=(1, 1), padding='SAME')
output = layer(image)
```

```python
plt.subplot(121)
plt.imshow(image[0, :, :, 0], 'gray')
plt.subplot(122)
plt.imshow(output[0, :, :, 0], 'gray')
plt.show()
```

![](/images/ai/dev/6.png)

weight 불러오기

```python
weight = layer.get_weights()[0]

plt.figure(figsize=(15, 5))
plt.subplot(131)
plt.hist(output.numpy().ravel(), range=[-2, 2])
plt.ylim(0, 100)
plt.subplot(132)
plt.title(weight.shape)
plt.imshow(weight[:, :, 0, 0], 'gray')
plt.subplot(133)
plt.title(output.shape)
plt.imshow(output[0, :, :, 0], 'gray')
plt.colorbar()
plt.show()
```

![](/images/ai/dev/7.png)

### Activation Function

0 미만의 값들을 0으로 바꿔준다.
![](/images/ai/dev/8.png)

tf.keras.layers.ReLU

```python
import numpy as np

act_layer = tf.keras.layers.ReLU()
act_output = act_layer(output)
np.min(act_output), np.max(act_output)

# Out
(0.0, 244.73064) # 0미만 값들이 0으로 바뀜
```

```python
plt.figure(figsize=(15, 5))
plt.subplot(121)
plt.hist(act_output.numpy().ravel(), range=[-2, 2])
plt.ylim(0, 100)

plt.subplot(122)
plt.title(act_output.shape)
plt.imshow(act_output[0, :, :, 0], 'gray')
plt.colorbar()
plt.show()
```

![](/images/ai/dev/9.png)

### Pooling

강조되는 것들만 압축한다.

![](/images/ai/dev/10.png)

tf.keras.layers.MaxPool2D

```python
pool_layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='SAME')
pool_output = pool_layer(act_output)
pool_output.shape

# Out
TensorShape([1, 14, 14, 3])
```

```python
plt.figure(figsize=(15, 5))
plt.subplot(121)
plt.hist(pool_output.numpy().ravel(), range=[-2, 2])
plt.ylim(0, 100)

plt.subplot(122)
plt.title(pool_output.shape)
plt.imshow(pool_output[0, :, :, 0], 'gray')
plt.colorbar()
plt.show()
```

![](/images/ai/dev/11.png)

### Fully Connected

![](/images/ai/dev/12.png)

```python
y = wX + b
```

#### Flatten

![](/images/ai/dev/13.png)

tf.keras.layers.Flatten

```python
layer = tf.keras.layers.Flatten()
flatten = layer(output)
flatten.shape

# Out
TensorShape([1, 2352]) # 28 * 28 * 3

output.shape

# Out
TensorShape([1, 28, 28, 3])
```

```python
plt.figure(figsize=(10, 5))
plt.subplot(211)
plt.hist(flatten.numpy().ravel())
plt.subplot(212)
plt.imshow(flatten[:, :100])
plt.show()
```

![](/images/ai/dev/14.png)

#### Dense

하나씩 연결하겠다는 의미이다.

![](/images/ai/dev/15.png)

tf.keras.layers.Dense

```python
layer = tf.keras.layers.Dense(32, activation='relu')
output = layer(flatten)
output.shape

# Out
TensorShape([1, 32]) # 32로 줄어들었음
```

#### DropOut

학습할 때만 랜덤하게 끊어준다. 학습이 끝나면 다시 복구시킨다.

![](/images/ai/dev/16.png)

tf.keras.layers.Dropout

```python
# 0.7은 비율이다. 얼마나 끊을 것인지 살릴 것인지
layer = tf.keras.layers.Dropout(0.7)
output = layer(output)
output.shape

# Out
TensorShape([1, 32])
```

### Build Model

![](/images/ai/dev/17.png)

```python
from tensorflow.keras import layers

input_shape = (28, 28, 1)
num_classes = 10

inputs = layers.Input(shape=input_shape)

# Feature Extraction
net = layers.Conv2D(32, 3, padding='SAME')(inputs)
net = layers.Activation('relu')(net)
net = layers.Conv2D(32, 3, padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPool2D(2, 2)(net)
net = layers.Dropout(0.25)(net)

net = layers.Conv2D(64, 3, padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.Conv2D(64, 3, padding='SAME')(net)
net = layers.Activation('relu')(net)
net = layers.MaxPool2D(2, 2)(net)
net = layers.Dropout(0.25)(net)

# Fully Connected
net = layers.Flatten()(net)
net = layers.Dense(512)(net)
net = layers.Activation('relu')(net)
net = layers.Dropout(0.25)(net)
net = layers.Dense(num_classes)(net)
net = layers.Activation('softmax')(net)

model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic-CNN')
model.summary()
```

```python
# Out
Model: "Basic-CNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 28, 28, 1)]       0
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 28, 28, 32)        320
_________________________________________________________________
activation_8 (Activation)    (None, 28, 28, 32)        0
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 28, 28, 32)        9248
_________________________________________________________________
activation_9 (Activation)    (None, 28, 28, 32)        0
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0
_________________________________________________________________
dropout_5 (Dropout)          (None, 14, 14, 32)        0
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 14, 14, 64)        18496
_________________________________________________________________
activation_10 (Activation)   (None, 14, 14, 64)        0
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 14, 14, 64)        36928
_________________________________________________________________
activation_11 (Activation)   (None, 14, 14, 64)        0
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 7, 7, 64)          0
_________________________________________________________________
dropout_6 (Dropout)          (None, 7, 7, 64)          0
_________________________________________________________________
flatten_4 (Flatten)          (None, 3136)              0
_________________________________________________________________
dense_3 (Dense)              (None, 512)               1606144
_________________________________________________________________
activation_12 (Activation)   (None, 512)               0
_________________________________________________________________
dropout_7 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_4 (Dense)              (None, 10)                5130
_________________________________________________________________
activation_13 (Activation)   (None, 10)                0
=================================================================
Total params: 1,676,266
Trainable params: 1,676,266
Non-trainable params: 0
_________________________________________________________________
```
